\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[document]{ragged2e}
\usepackage{hyperref}

\title{Documentation for schemaFuzz}
\author{Ulrich "Feideus" Erwan}

\begin{document}

	
\maketitle Documentation For SchemaFuzz
	\section{Summary?}
		This document actually needs a front page.
	\section{Introduction}
	
SchemaFuzz is a free software command line tool incorporated inside the GnuTaler package designed to properly fuzz databases.
Traditionnal fuzzing is defined as "testing an automated software testing technique that involves providing invalid, unexpected, or random data as inputs to a computer program". SchemaFuzz uses this principle and applies it to the database field.
Where a traditionnal fuzzer would send malformed input to a program, SchemaFuzz modifies the content of a database to test that program's behavior when stumbling on such unexpected data. \\*
Obviously, this tool is meant to be used as a mean of debugging as the goal is to pop buggs or put into light the security breaches that the code may contain regarding the retrieving, usage and saving of a database's content.
As this tool is being developped as a master's thesis project, its current state is far from being finished and there are many options and optimisations that deserve to be implemented that are not yet available.
These future/missing features will be detailed and discussed in a dedicated section.

	\section{Usage}
		\subsection{prerequisites}
			SchemaFuzz requires the presence of a list of libraries to work properly which are :
			\begin{itemize}
			\item org.apache.commons.math3 >= 3.6
			available at \\*
			\url{https://commons.apache.org/proper/commons-math/download_math.cgi}			
			\end{itemize}
The library has to be installed in the maven repository to be available. The instructions detailed at the following address explain how to do that. futher information can be found on the official maven website.\\*

			\url{https://www.mkyong.com/maven/how-to-include-library-manully-into-maven-local-repository/}
			
		\subsection{setting up the code}
			Once all the depencies have been installed successfully, clone the source available on the official git taler repository \\*
			\url{https://git.taler.net/schemafuzz.git}
			\begin{verbatim}
			 git clone https://git.taler.net/schemafuzz.git
			\end{verbatim}
			
the folder containing the code shoud hold the rights for reading writing and executing (rwx) for the user that plans to run the tool.
if this is not the case, you can give these rights like so
			\begin{verbatim}
			sudo chmod -R 700 schemafuzz
			\end{verbatim}
		\subsection{Building}
SchemaFuzz is using maven for building and library management purposes.
Therefore, using the maven command line building script is way to go.
Standard way of building :\\*
			\begin{verbatim}
			./mvnw package
			\end{verbatim}
				
This maven building method also offers alternative instructions for 	more precise/refined way of building as well as compilation and test 
launching options (those should only be intresting for the contributors).

Launching the test suit :\\*
			\begin{verbatim}
			./mvnw test
			\end{verbatim}
Compiling the code :\\*		
			\begin{verbatim}
			./mvnw compile
			\end{verbatim}
		
Other usefull commands: \\*		
		
			\begin{verbatim}
			./mvnw clean
			\end{verbatim}
			\begin{verbatim}
			./mvnw validate
			\end{verbatim}
			\begin{verbatim}
			./mvnw deploy
			\end{verbatim}
		
		\subsection{Setting up the database}	
	
Launch the "dbConfigure" script.
			\begin{verbatim}
				./dbConfigure
			\end{verbatim}		 
		
	\section{Design}
		\subsection{Generic explanation}
SchemaFuzz implementation is based on some bits of the SchemaSpy project source code.
The majority of this project is built on top of this already existing code and is organised as follows :
The mutation/data-set used as a way to store the imputs,outputs and other intresting data from the modification that was performed on the target database,
the mutation Tree, used to store those objects coherently, and an analyser that scores the mutations to influence the paths that will be explored afterwards. This organisation will be detailled and discussed in the following sections.
		\subsection{SchemaSpy legacy/metadata extraction}
SchemaSpy source code has provided the metadata extraction routine. This routine retrieves all the relevant information about the target database. These informations include data types, table and table column names, views and foreign/primary key constraints. Having this pool of metadata allows the program to properly frame what the possibilities are in terms of modifications (called mutations) as well as dealing with the possible constraints on the different tables. 
This part of the code also parses the arguments given as inputs and initialises the database connection.
In order to do that, the user shall provide this set of mandatory database related arguments
			\begin{itemize}
 				\item The driver to the corresponding database RDBMS (only support PostGres at the moment)
 				\item The credentials to be used to access the database.
 				\item The name of the database (duh)
			\end{itemize}
		\subsection{SchemaFuzz Core}		
			\subsubsection{Constrains}
The target database often contains contraints on one or several tables. These constraints have to be taken into account in the process of fabricating mutations as most of the time they restrict the possible values that the pointed field can take. This restriction can take the shape of a \underline {Not Null} constraint, \underline{Check} constraint, {Foreign key} constraint (value has to exist in some other table's field) or \underline{Primary key} constraint (no doublets of value allowed). These constraints are stored as Java objects instanciated from the corresponding class.
%(add constraints class diagram here)
The last two ones are the problematic ones. They imply specific work before applying any mutations to make sure that the value respect all the restrictions. before doing anything else after the metadata extraction is done, SchemaFuzz performs an update of all the existing constraints on the database to add the CASCADE clause. This allows the values bonded by a foreign key constraints to take effect. This update reverts to take the constraints back to their initial state before the program exits.
				\paragraph{Primary key contraints (PKC)} :
The primary key constraints require an extra DB query that checks the existence of the value in the column. If the value already exists (the query's result is not empty), the mutation will be dropped before being executed.
				\paragraph{Foreign key contraints (FKC)} :
The foreignKey constraint is the trickiest one. Its inherent nature bonds two values of different table column where the value being referenced is called the father, and the referecing field, the child. To be precise, in order to change one of the two values, the other has to be changed accordingly in the same statement.SchemaFuzz uses the power of the CASCADE clause to make the change possible. This clause allows the DRBMS to automaticly change the value of the child if the father has been changed.
This mechanic allows to change any of the bounded values by changing the father's value.
To do so, the software has a way to tranfert the mutation from a child to its parent (called the mutationTransfert).

  				
			\subsubsection{Mutations}
				\paragraph{Creating malformed data} 
As the goal of running this tool is to submit unexpected or invalid data to the target software it is necessary to understand what t
Fuzzing a complex type such a timestamp variable has nothing to do with fuzzing a trivial boolean. In practice, A significant part o
and this matter could absolutly be the subject of a more abstract work. We focused here on a very simple approach (as a first step.
After retrieving the current row being fuzzed (may it be a new row or a previously fuzzed row), the algorithm explores the different
The algorithm then builds the possible modification for each of the fields for the current row.
At the moment, the supported types are : % add a list of the supported types.
More primitives types will be added in the future.
The possible modifications that this tool can produce at the moment are : % add complete list of the modifications that CAN be gener$
				Int Types:
				\begin{itemize}
		
					\item Extreme values (0-32676 (int) etc...)
					\item Random value (0<value<32676 (int) etc...)
					\item Increment/Decrement the existing value (332 -> 333 OR 332 -> 331)
				\end{itemize}
				String Types:
				\begin{itemize}
			
					\item Change string to "aaa" ("Mount Everest" -> "aaa")
					\item Increment/Decrement ASCII character at a random position in the string ("Mount Everest" -> "Mount Fverest")
					Boolean
					\item Swaping the existing value (F -> T OR T -> F)
					\end{itemize}
					Date Types : (! IMPLEMENTED BUT NOT FULLY FUNCTIONNAL)					
					\begin{itemize}
					\item Increment/Decrement date by 1 day/minutes depending on the precision of the date
					\item Set date to 00/00/0000
				\end{itemize}
Obviously, these "abnormal" values might in fact be totally legit in some cases. in that case the analyzer 
will rank the mutation rather poorly, which will lead to this tree path not being very likely to be developped further more.
				\\*
				\paragraph{Sql handling}
All the SQL statements are generated within the code. This means that the data concerning the current and future state of the mutations have to be very precise. Otherwise, the SQL statement is very likely to fail. Sadly, since SchemaFuzz only supports postgreSQL, the implemented synthax follow the one of postgres
DBMS. This is already a very big axis for future improvements and will be detailled in the dedicated section.
The statement is built to target the row as precisely as possible, meaning that it uses all of the non fuzzed values from the row to avoid updating other row accidently. Only the types that can possibly be fuzzed will be used in the building of the SQL statement. Since this part of the code is very delicate in the sense that it highly depends on an arbitrary large pool of variables from various types it is a good bugg provider. 
				
				\paragraph{Injecting}
				\paragraph{Special Cases(MutationTransfert)}
				\paragraph{Do/Undo routine}
			\subsubsection{TreeBased data structure}
				\paragraph{Weight}
				\paragraph{Path}
			\subsubsection{The analyzer}
				\paragraph{Stack Trace Parser}
				\paragraph{Hashing}
				\paragraph{The Scoring mechanism}
				\paragraph{Clustering Mutations}
		\subsection{Known issues}		
			\subsubsection{Failing Mutations}
			\subsubsection{Foreign Key constraints}
			\subsubsection{Tests}
	\section{Upcomming features and changes}
This section will provide more insights on the future features that might/may/will be implemented as well as the changes in the existing code.
Any sugestion will be greatly appriciated as long as it is relevent and well argumented. All the relevent information regarding the contributions are detailled in the so called section.
	
		\subsection{Code coverage}
Debate code coverage here.
		\subsection{Centralised anonymous user data}
Debate computing the best types or mutations and configurations (tree depth etc...) as user data for SchemaFuzz
		
	\section{Contributing}
You can send your ideas at  \\*
		\url{erwan.ulrich@gmail.com}
Or directly create a pull request on the official repository to edit this document and/or the code itself
	\section{Conclusion}
\end{document} 
